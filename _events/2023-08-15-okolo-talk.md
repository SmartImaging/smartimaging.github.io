---
title: "AI Explainability in the Global South: Developing an Inclusive Praxis for Emerging Technology Users"
date: 2023-08-15
time: 12-1 p.m. EST
location: Online
thumbnail: /assets/images/events/okolo-talk-thumb.jpg
alt: A photograph of a healthcare worker examining medical data on a tablet
registerurl: https://www.eventbrite.com/e/matching-metadata-text-for-the-enriching-exhibition-scholarship-project-tickets-630969124637?aff=ebdsoporgprofile
categories:
  - Talk
tags:
  - Accessibility
  - Artificial Intelligence
teaser: >
  In this virtual presentation, Dr. Chinasa T. Okolo will discuss her research on developing an inclusive artificial intelligence praxis for technology users in the Global South. Focusing on low-resource healthcare settings in rural India, Dr. Okolo will explore how these frontline community health workers use and value AI, and will examine how to construct AI tools with these users in mind.
---

### Overview
In this virtual presentation, Dr. Chinasa T. Okolo will discuss her research on developing an inclusive praxis for emerging technology users, such as community health workers in low-resource healthcare settings.  

As researchers and technology companies rush to develop artificial intelligence (AI) applications that address social impact problems in domains such as agriculture, education, and healthcare, Dr. Okolo argues that it is critical to consider the needs of users like community health workers (CHWs), who will be increasingly expected to operate tools that incorporate these technologies.  

Dr. Okolo's research shows that CHWs have low levels of AI knowledge, form incorrect mental models about how AI works, and at times, may trust algorithmic decisions more than their own. This is concerning, given that AI applications targeting the work of CHWs are already in active development, and early deployments in low-resource healthcare settings have already reported failures that created additional workflow inefficiencies and inconvenienced patients. Explainable AI (XAI) can help avoid such pitfalls, but nearly all prior work has focused on users that live in relatively resource-rich settings (e.g., the US and Europe) and who arguably have substantially more experience with digital technologies overall and AI systems in particular.  

In her dissertation work, Dr. Okolo critically engages with CHWs and AI practitioners to investigate the feasibility of (X)AI in resource-constrained environments in the Global South and provide actionable recommendations for practitioners (designers, developers, researchers, etc.) interested in building tools accessible to users within these contexts.  

### About the Speaker
**Chinasa T. Okolo** is a recent Computer Science Ph.D. graduate from Cornell University and an incoming Fellow at the Brookings Institute. Her research interests include explainable AI, human-AI interaction, AI governance, and information and communication technologies for development (ICTD). Within these fields, she works on projects to understand how frontline healthcare workers in rural India perceive and value AI and examines how explainability can be best leveraged in AI-enabled technologies deployed throughout the Global South. Dr. Okolo also conducts research examining factors impacting the effective adoption and successful implementation of AI in Africa and has worked with international organizations such as the African Union to expand digital inclusion and develop strategic AI policy measures.  

### Event Details
**Time:**  
Tuesday, August 15, 2023  
12-1 p.m. EST  

**Location:**  
Online  

### Registration
This event is open to all, though registration is required. To register, visit the <a href='https://www.eventbrite.com/e/virtual-talk-ai-explainability-in-the-global-south-tickets-691753642767' target='_blank'>Eventbrite page for the talk</a>. Please note that this is a fully virtual event.  

*Be among the first to know when future workshops and events are announced by signing up for the <a href='https://subscribe.yale.edu/browse?search=digital+humanities' target='_blank'>DHLabâ€™s newsletter</a>.*
